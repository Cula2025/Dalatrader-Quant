from __future__ import annotations
import os, math, json, inspect, traceback, datetime as dt
from typing import Any, Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError

import pandas as pd
import numpy as np
import streamlit as st

# ---------- trygg debug-import ----------
try:
    from app.debuglog import setup_debug_ui, log_info, log_warn, log_error, df_brief
except Exception:
    def setup_debug_ui(*a, **k): pass
    def log_info(*a, **k): pass
    def log_warn(*a, **k): pass
    def log_error(*a, **k): pass
    def df_brief(x, rows=5, cols=8):
        try: return x.iloc[:rows, :cols]
        except Exception: return x

# ---------- Page / theme ----------
st.set_page_config(page_title="PortfÃ¶lj", page_icon="ðŸ“¦", layout="wide")
PRIMARY = "#1f6feb"; ACCENT = "#d29922"
st.markdown(f"""
<style>
:root {{ --primary:{PRIMARY}; --accent:{ACCENT}; }}
.block-container {{ padding-top: .5rem; }}
.stButton>button {{ background: var(--primary); color: white; border: 0; }}
</style>
""", unsafe_allow_html=True)

DATA_DIR = "trader/outputs/opt_results"
OUT_DIR  = "trader/outputs"
os.makedirs(OUT_DIR, exist_ok=True)

# ---------- Helpers (JSON) ----------
def _fix_columns(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).replace("\ufeff", "").strip() for c in df.columns]
    # Normalisera Ticker
    if "Ticker" not in df.columns:
        for c in list(df.columns):
            if c.lower() == "ticker":
                df.rename(columns={c:"Ticker"}, inplace=True)
                break
    return df

def _coerce_bools(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:
    for c in cols:
        if c in df.columns:
            df[c] = (
                df[c].astype(str).str.strip().str.lower()
                .replace({"true": True, "false": False, "1": True, "0": False, "yes": True, "no": False})
            )
    return df

def _flatten_row(d: Dict[str, Any]) -> Dict[str, Any]:
    """Flattena vanliga fÃ¤lt (t.ex. params) och mappa namnâ†’Ticker/ticker."""
    out = dict(d) if isinstance(d, dict) else {}
    # Ticker-kÃ¤lla
    for key in ("Ticker","ticker","name"):
        if key in out and isinstance(out[key], str) and out[key].strip():
            out["Ticker"] = out[key].strip()
            break
    # Flatten params
    if isinstance(out.get("params"), dict):
        for k, v in out["params"].items():
            out.setdefault(k, v)
        del out["params"]
    # Flatten config
    if isinstance(out.get("config"), dict):
        for k, v in out["config"].items():
            out.setdefault(k, v)
        del out["config"]
    return out

def _json_to_df(obj: Any) -> pd.DataFrame:
    """StÃ¶der:
       - lista av rader
       - {"profiles":[...]} eller {"rows":[...]} eller {"items":[...]} eller {"results":[...]}
       - dict med tickers som nycklar
       - json-lines (hanteras innan via text-split)
    """
    if isinstance(obj, list):
        rows = [_flatten_row(x) for x in obj if isinstance(x, dict)]
        return pd.DataFrame(rows)
    if isinstance(obj, dict):
        # vanliga nycklar med listor
        for k in ("profiles","rows","items","results","data"):
            if isinstance(obj.get(k), list):
                rows = [_flatten_row(x) for x in obj[k] if isinstance(x, dict)]
                return pd.DataFrame(rows)
        # dict med tickers som nycklar
        if all(isinstance(v, dict) for v in obj.values()):
            rows = []
            for tck, payload in obj.items():
                rd = _flatten_row(payload)
                rd.setdefault("Ticker", tck)
                rows.append(rd)
            return pd.DataFrame(rows)
    # OkÃ¤nt format -> tom DF
    return pd.DataFrame([])

def load_opt_json_any(path: str) -> pd.DataFrame:
    """LÃ¤s .json eller .jsonl/.ndjson robust."""
    with open(path, "r", encoding="utf-8-sig") as f:
        text = f.read().strip()
    if not text:
        return pd.DataFrame()
    # JSON-Lines?
    if "\n" in text and text.lstrip().startswith("{") and not text.strip().startswith("["):
        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
        rows = []
        for ln in lines:
            try:
                rows.append(_flatten_row(json.loads(ln)))
            except Exception:
                continue
        return _fix_columns(pd.DataFrame(rows))
    # Vanlig JSON
    try:
        obj = json.loads(text)
    except Exception as e:
        log_error(f"JSON parse error in {path}: {e}")
        return pd.DataFrame()
    df = _json_to_df(obj)
    df = _fix_columns(df)
    # Konvertera typer
    num_cols = [
        "rsi_window","rsi_min","rsi_max","trend_ma_window","breakout_lookback","exit_lookback",
        "macd_fast","macd_slow","macd_signal","sl","fee","slip_bps","max_hold_days",
    ]
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    df = _coerce_bools(df, ["use_rsi_filter","use_trend_filter","use_macd_filter","use_sl","use_tp"])
    return df

def _now_str() -> str:
    return dt.datetime.now().strftime("%Y%m%d_%H%M%S")

@st.cache_data(ttl=300, show_spinner=False)
def list_json_files(_data_dir_mtime: float) -> List[str]:
    if not os.path.isdir(DATA_DIR):
        return []
    return sorted([f for f in os.listdir(DATA_DIR) if f.lower().endswith((".json",".jsonl",".ndjson"))])

def _data_dir_mtime() -> float:
    try:
        return max(os.path.getmtime(os.path.join(DATA_DIR, f)) for f in os.listdir(DATA_DIR))
    except Exception:
        return 0.0

# ---------- Motor-detektering ----------
def _detect_engine() -> Tuple[Optional[Any], str]:
    candidates = [
        ("app.portfolio_engine", "run_for_ticker"),
        ("app.portfolio_backtest", "run_for_ticker"),
        ("app.portfolio_backtest", "run_backtest"),
        ("app.backtest", "run"),
        ("app.backtest", "run_backtest"),
        ("app.engine", "run_backtest"),
        ("app.backtester", "run_single"),
    ]
    for mod, attr in candidates:
        try:
            m = __import__(mod, fromlist=[attr])
            fn = getattr(m, attr, None)
            if callable(fn):
                return fn, f"{mod}.{attr}"
        except Exception:
            continue
    return None, ""

ENGINE_FN, ENGINE_NAME = _detect_engine()

def _filter_kwargs_by_signature(fn, row: pd.Series) -> Tuple[dict, Optional[str]]:
    try:
        sig = inspect.signature(fn)
    except Exception as e:
        return {}, f"inspect.signature fail: {e}"
    accepted = {p.name for p in sig.parameters.values()}
    row_dict = {k: row.get(k) for k in row.index}
    # normalisera MA-typ
    if "trend_ma_type" in row_dict and isinstance(row_dict["trend_ma_type"], str):
        row_dict["trend_ma_type"] = row_dict["trend_ma_type"].upper().strip()
    # NaN -> None
    for k, v in list(row_dict.items()):
        if isinstance(v, float) and math.isnan(v):
            row_dict[k] = None
    kwargs = {k: v for k, v in row_dict.items() if k in accepted}
    # ticker
    if "ticker" in accepted and "ticker" not in kwargs:
        t = row.get("Ticker")
        if isinstance(t, str) and t:
            kwargs["ticker"] = t
    return kwargs, None

def _run_one_row(row: pd.Series) -> Dict[str, Any]:
    tck = row.get("Ticker", "?")
    if ENGINE_FN is None:
        return {"Ticker": tck, "Trades": 0, "Ret%": float("nan"), "MaxDD%": float("nan"), "Note": "No engine detected"}
    try:
        kwargs, err = _filter_kwargs_by_signature(ENGINE_FN, row)
        if err: log_warn(f"Signature issue for {tck}: {err}")
        if "ticker" not in kwargs:
            try:
                res = ENGINE_FN(row.get("Ticker"))
            except TypeError:
                res = ENGINE_FN(**kwargs)
        else:
            res = ENGINE_FN(**kwargs)

        result = {"Ticker": tck}
        if isinstance(res, dict):
            for k in ("trades","n_trades","Trades"):
                if k in res:
                    result["Trades"] = int(res[k]) if pd.notna(res[k]) else 0
                    break
            for k in ("ret","return","total_return","Ret%","cagr","CAGR","score"):
                if k in res and pd.notna(res[k]):
                    val = float(res[k])
                    if -1.0 <= val <= 1.0 and abs(val) < 0.99:
                        val *= 100.0
                    result["Ret%"] = round(val, 2); break
            for k in ("maxdd","max_drawdown","mdd","MaxDD%"):
                if k in res and pd.notna(res[k]):
                    val = float(res[k])
                    if -1.0 <= val <= 1.0 and abs(val) < 0.99:
                        val *= 100.0
                    result["MaxDD%"] = round(val, 2); break
            for k, v in res.items():
                if k not in result:
                    result[k] = v
        else:
            result.update({"Trades": 0, "Ret%": float("nan"), "MaxDD%": float("nan")})
        result.setdefault("Trades", 0)
        result.setdefault("Ret%", float("nan"))
        result.setdefault("MaxDD%", float("nan"))
        return result
    except Exception as e:
        log_error(f"Exception {tck}: {e}\n{traceback.format_exc()}")
        return {"Ticker": tck, "Trades": 0, "Ret%": float("nan"), "MaxDD%": float("nan"), "Error": str(e)}

def run_parallel(df: pd.DataFrame, max_workers: int, timeout_s: int) -> pd.DataFrame:
    rows: List[Dict[str, Any]] = []
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futs = {ex.submit(_run_one_row, r): r.get("Ticker","?") for _, r in df.iterrows()}
        for fut in as_completed(futs):
            t = futs[fut]
            try:
                row = fut.result(timeout=timeout_s)
            except TimeoutError:
                row = {"Ticker": t, "Trades": 0, "Ret%": float("nan"), "MaxDD%": float("nan"), "Error": "Timeout"}
            except Exception as e:
                row = {"Ticker": t, "Trades": 0, "Ret%": float("nan"), "MaxDD%": float("nan"), "Error": f"Exception: {e}"}
            rows.append(row)
    return pd.DataFrame(rows)

# ---------- UI ----------
st.title("ðŸ“¦ PortfÃ¶lj")
setup_debug_ui(st)

mtime_key = _data_dir_mtime()
files = list_json_files(_data_dir_mtime=mtime_key)
left, right = st.columns([2,1])

with left:
    if not files:
        st.warning(f"Hittar inga JSON i `{DATA_DIR}`.")
        st.stop()
    picked = st.selectbox("VÃ¤lj optimeringsfil (JSON)", files, index=len(files)-1)
with right:
    st.caption("Prestanda")
    workers = st.slider("Parallella trÃ¥dar", 1, 16, 4)
    timeout_s = st.slider("Timeout per aktie (s)", 5, 180, 25)

json_path = os.path.join(DATA_DIR, picked)
df = load_opt_json_any(json_path)

if df.empty or "Ticker" not in df.columns:
    st.error("Kunde inte lÃ¤sa JSON eller saknar kolumnen **Ticker**.")
    if not df.empty:
        st.dataframe(df_brief(df, rows=20, cols=10), width="stretch")
    st.stop()

with st.expander("FÃ¶rhandsgranska data", expanded=False):
    st.dataframe(df_brief(df, rows=20, cols=12), width="stretch")

st.caption(f"Motor: {'â€”' if ENGINE_FN is None else ENGINE_NAME}")

if st.button("KÃ¶r portfÃ¶lj-backtest"):
    with st.spinner("KÃ¶r backtest i batchâ€¦"):
        out = run_parallel(df, workers, timeout_s)

    if out.empty:
        st.info("Inga resultat.")
    else:
        if "Ret%" in out.columns:
            out = out.sort_values(by="Ret%", ascending=False)
        st.subheader("Resultat")
        st.dataframe(out, width="stretch")

        if "Ret%" in out.columns and "Ticker" in out.columns:
            top5 = out.sort_values(by="Ret%", ascending=False).head(5)
            cols = [c for c in ["Ticker","Trades","Ret%","MaxDD%"] if c in top5.columns]
            st.markdown("**Topp 5 signaler**")
            st.table(top5[cols])

        save_path = os.path.join(OUT_DIR, f"portfolio_result_{dt.datetime.now():%Y%m%d_%H%M%S}.csv")
        out.to_csv(save_path, index=False, encoding="utf-8-sig")
        st.success(f"Sparat: `{save_path}`")

st.caption(f"KÃ¤lla: `{json_path}` â€¢ Output: `{OUT_DIR}`")
