from __future__ import annotations
import os, re, json, ast, inspect, traceback, datetime as dt
from typing import Any, Dict, List, Optional, Tuple
import pandas as pd
import numpy as np
import streamlit as st

# --- failsafe debug ---
try:
    from app.debuglog import setup_debug_ui, log_info, log_warn, log_error, df_brief
except Exception:
    def setup_debug_ui(*a, **k): pass
    def log_info(*a, **k): pass
    def log_warn(*a, **k): pass
    def log_error(*a, **k): pass
    def df_brief(x, rows=5, cols=8):
        try: return x.iloc[:rows, :cols]
        except Exception: return x

# ev. dataloader fallback fr√•n __init__/btwrap
try:
    _load_df_any_alias
except NameError:
    def _load_df_any_alias(*args, **kwargs):
        return kwargs.get("df", pd.DataFrame())

st.set_page_config(page_title="Portfolio (profiler)", page_icon="üíº", layout="wide")
st.title("üíº Portfolio (profiler)")
setup_debug_ui(st)

OUT_DIR = "trader/outputs"; os.makedirs(OUT_DIR, exist_ok=True)
DEFAULT_DIR = "/srv/trader/app/profiles"

# -------------------- T√•lig profil-l√§sare --------------------
TICKER_KEYS = ("Ticker","ticker","symbol","code","name","shortName","short_name")

def _strip_comments_and_trailing_commas(text: str) -> str:
    text = re.sub(r"//.*?$", "", text, flags=re.MULTILINE)
    text = re.sub(r"/\*.*?\*/", "", text, flags=re.DOTALL)
    text = re.sub(r",\s*([}\]])", r"\1", text)
    return text.strip()

def _try_ast_literal_eval(text: str) -> Any:
    t = re.sub(r"\btrue\b","True", re.sub(r"\bfalse\b","False", re.sub(r"\bnull\b","None", text, flags=re.I), flags=re.I), flags=re.I)
    try: return ast.literal_eval(t)
    except Exception: return None

def _flatten(d: Dict[str, Any]) -> Dict[str, Any]:
    d = dict(d)
    for k in TICKER_KEYS:
        v = d.get(k)
        if isinstance(v, str) and v.strip():
            d["Ticker"] = v.strip(); break
    for nest in ("params","config","settings","options"):
        if isinstance(d.get(nest), dict):
            for k,v in d[nest].items(): d.setdefault(k,v)
            del d[nest]
    return d

def _looks_single(d: Dict[str, Any]) -> bool:
    return any(k in d for k in TICKER_KEYS) or any(k in d for k in ("params","config","settings","options"))

def _infer_ticker_from_filename(path: str) -> Optional[str]:
    nm = os.path.splitext(os.path.basename(path))[0]
    return (nm.split("_")[0] if "_" in nm else nm).strip() or None

def _json_to_rows(obj: Any) -> List[Dict[str, Any]]:
    if isinstance(obj, list):
        return [_flatten(x) for x in obj if isinstance(x, dict)]
    if isinstance(obj, dict):
        for k in ("profiles","rows","items","results","data","list","values"):
            if isinstance(obj.get(k), list):
                return [_flatten(x) for x in obj[k] if isinstance(x, dict)]
        if _looks_single(obj): return [_flatten(obj)]
        if obj and all(isinstance(v, dict) for v in obj.values()):
            rows=[]
            for tck,payload in obj.items():
                r=_flatten(payload)
                if "Ticker" not in r and isinstance(tck,str) and tck.strip(): r["Ticker"]=tck.strip()
                rows.append(r)
            return rows
    return []

def parse_json_file(path: str) -> List[Dict[str, Any]]:
    try:
        text = open(path,"r",encoding="utf-8-sig").read().strip()
        if not text: return []
        # NDJSON?
        if "\n" in text and text.lstrip().startswith("{") and not text.strip().startswith("["):
            out=[]
            for ln in [ln.strip() for ln in text.splitlines() if ln.strip()]:
                try: out.append(_flatten(json.loads(ln))); continue
                except Exception: pass
                ln2=_strip_comments_and_trailing_commas(ln)
                try: out.append(_flatten(json.loads(ln2))); continue
                except Exception: pass
                obj=_try_ast_literal_eval(ln2)
                if isinstance(obj, dict): out.append(_flatten(obj))
            return out
        # vanlig JSON / tolerant
        try: obj=json.loads(_strip_comments_and_trailing_commas(text))
        except Exception: obj=_try_ast_literal_eval(_strip_comments_and_trailing_commas(text))
        return _json_to_rows(obj) if obj is not None else []
    except Exception as e:
        log_warn(f"Parse fail {path}: {e}")
        return []

@st.cache_data(ttl=120, show_spinner=False)
def list_json_files(dir_path: str) -> List[str]:
    if not os.path.isdir(dir_path): return []
    return sorted([f for f in os.listdir(dir_path) if f.lower().endswith((".json",".jsonl",".ndjson"))])

def build_profiles_df(dir_path: str, files: List[str]) -> pd.DataFrame:
    rows=[]
    for f in files:
        p=os.path.join(dir_path,f)
        recs=parse_json_file(p)
        if recs:
            for r in recs:
                rr=dict(r); rr["source_file"]=f
                if not rr.get("Ticker"): rr["Ticker"]=_infer_ticker_from_filename(p) or ""
                rows.append(rr)
        else:
            rows.append({"Ticker": _infer_ticker_from_filename(p) or "", "source_file": f, "_note": "empty/parse-fail"})
    df=pd.DataFrame(rows)
    if not df.empty:
        df.columns=[str(c).replace("\ufeff","").strip() for c in df.columns]
        first=[c for c in ("Ticker","source_file") if c in df.columns]
        df=df[first + [c for c in df.columns if c not in first]]
    return df

# -------------------- Motor / kurvor --------------------
def _detect_engine() -> Tuple[Optional[Any], str]:
    cands=[("app.portfolio_engine","run_for_ticker"),
           ("app.portfolio_backtest","run_for_ticker"),
           ("app.backtest","run_backtest"),
           ("app.backtester","run_single")]
    for mod,attr in cands:
        try:
            m=__import__(mod, fromlist=[attr]); fn=getattr(m,attr,None)
            if callable(fn): return fn, f"{mod}.{attr}"
        except Exception: continue
    return None,""

def _series_from_engine_result(res: Any) -> Optional[pd.Series]:
    if res is None: return None
    s=None
    if isinstance(res, dict):
        candidates=["equity","curve","balance","cumret","portfolio","portfolio_value","equity_curve"]
        for k in candidates:
            v=res.get(k)
            if v is None: continue
            if isinstance(v, dict):
                try: s=pd.Series(v); break
                except Exception: pass
            if isinstance(v, list) and v:
                try:
                    if isinstance(v[0], dict):
                        key_date=None; key_val=None
                        for kd in ("date","Date","ts","timestamp"):
                            if kd in v[0]: key_date=kd; break
                        for kv in ("equity","value","val","y","close","Close"):
                            if kv in v[0]: key_val=kv; break
                        if key_date and key_val:
                            idx=pd.to_datetime([x[key_date] for x in v])
                            vals=[x[key_val] for x in v]
                            s=pd.Series(vals, index=idx); break
                    else:
                        s=pd.Series(v); break
                except Exception: pass
    if s is None and isinstance(res, pd.Series): s=res
    if s is None and isinstance(res, pd.DataFrame):
        for c in ("equity","value","val","close","Close"):
            if c in res.columns:
                try: s=res[c]; break
                except Exception: pass
    if s is None: return None
    s=s.dropna()
    if len(s)>0 and s.iloc[0]>0: s = s / float(s.iloc[0])
    try: s.index = pd.to_datetime(s.index)
    except Exception: pass
    return s.sort_index()

def _call_engine_curve(fn, ticker: str) -> Optional[pd.Series]:
    try:
        sig=inspect.signature(fn); names={p.name for p in sig.parameters.values()}
        if "ticker" in names: res=fn(ticker=ticker)
        elif "symbol" in names: res=fn(symbol=ticker)
        elif "code" in names: res=fn(code=ticker)
        else: res=fn(ticker)
    except Exception as e:
        log_warn(f"Engine call failed for {ticker}: {e}"); 
        return None
    return _series_from_engine_result(res)

def _load_price_series(ticker: str) -> Optional[pd.Series]:
    try:
        df=_load_df_any_alias(symbol=ticker) or _load_df_any_alias(ticker=ticker) or _load_df_any_alias(code=ticker)
        if isinstance(df, pd.DataFrame) and not df.empty:
            for c in ("Adj Close","adj_close","Close","close","c"):
                if c in df.columns:
                    s=df[c].astype(float).dropna(); break
            else:
                if all(x in df.columns for x in ("open","high","low","close")):
                    s=df["close"].astype(float).dropna()
                elif all(x in df.columns for x in ("Open","High","Low","Close")):
                    s=df["Close"].astype(float).dropna()
                else:
                    return None
            if len(s)==0: return None
            s.index=pd.to_datetime(df.index); s=s.sort_index()
            return (s / s.iloc[0]).rename(ticker)
    except Exception as e:
        log_warn(f"Price load failed for {ticker}: {e}")
    return None

def _build_equal_weight(curves: Dict[str,pd.Series]) -> Optional[pd.Series]:
    if not curves: return None
    all_idx=None
    for s in curves.values():
        all_idx = s.index if all_idx is None else all_idx.intersection(s.index)
    if all_idx is None or len(all_idx)==0:
        idx = sorted(set().union(*[set(s.index) for s in curves.values()]))
        df = pd.DataFrame({k: v.reindex(idx).ffill() for k,v in curves.items()})
    else:
        df = pd.DataFrame({k: v.reindex(all_idx) for k,v in curves.items()})
    df = df.dropna(how="all")
    if df.empty: return None
    w = np.ones(df.shape[1]) / df.shape[1]
    port = (df * w).sum(axis=1)
    if port.iloc[0] != 0: port = port / port.iloc[0]
    return port.rename("Portf√∂lj")

# -------------------- UI --------------------
tabs = st.tabs(["√ñversikt", "Universum", "Transaktioner"])

with tabs[0]:
    colL, colR = st.columns([3,1])
    with colL:
        data_dir = st.text_input("Datakatalog (JSON f√∂r profiler)", value=st.session_state.get("portfolio_dir", DEFAULT_DIR), key="portfolio_dir")
    with colR:
        profiles = DEFAULT_DIR
        if os.path.isdir(profiles) and st.button("Anv√§nd profiles/"):
            st.session_state["portfolio_dir"]=profiles; st.rerun()

    files = list_json_files(data_dir)
    if not files:
        st.warning(f"Inga JSON-filer i `{data_dir}`."); st.stop()

    picked = st.multiselect("V√§lj profilfiler", files, default=files)
    if not picked:
        st.info("V√§lj minst en fil."); st.stop()

    df_prof = build_profiles_df(data_dir, picked)
    if df_prof.empty or "Ticker" not in df_prof.columns:
        st.error("Kunde inte h√§mta profiler med Ticker."); st.stop()

    tickers = sorted(set([t for t in df_prof["Ticker"].astype(str).str.strip().tolist() if t]))
    st.caption(f"Hittade {len(tickers)} unika tickers.")

    with st.expander("‚öôÔ∏è Inst√§llningar", expanded=False):
        prefer_strategy = st.checkbox("Anv√§nd strategi-kurvor om tillg√§ngligt (annars Buy&Hold)", value=True)
        index_symbol = st.text_input("Indexsymbol (f√∂r bl√• 'OMXS30 (index)')", value="OMXS30")
        show_bh = st.checkbox("Visa Buy&Hold i grafen", value=True)
        start_date = st.date_input("Startdatum (valfritt)", value=None)
        run_btn = st.button("Bygg portf√∂lj")

    if run_btn:
        engine_fn, engine_name = _detect_engine() if prefer_strategy else (None,"")
        curves: Dict[str,pd.Series] = {}
        for t in tickers:
            s = _call_engine_curve(engine_fn, t) if engine_fn is not None else None
            if s is None: s = _load_price_series(t)
            if s is not None and len(s)>5:
                if start_date: s = s[s.index >= pd.Timestamp(start_date)]
                curves[t] = s

        if not curves:
            st.error("Hittade inga kurvor att rita."); st.stop()

        port = _build_equal_weight(curves)
        if port is None or port.empty:
            st.error("Kunde inte konstruera portf√∂ljen."); st.stop()

        idx_curve = None
        if index_symbol:
            idx_curve = _load_price_series(index_symbol)
            if idx_curve is not None and start_date:
                idx_curve = idx_curve[idx_curve.index >= pd.Timestamp(start_date)]

        bh = None
        if show_bh:
            bh_curves = {}
            for t in tickers:
                s=_load_price_series(t)
                if s is not None:
                    if start_date: s = s[s.index>=pd.Timestamp(start_date)]
                    bh_curves[t]=s
            bh = _build_equal_weight(bh_curves) if bh_curves else None
            if bh is not None: bh = bh.rename("Buy&Hold")

        import altair as alt
        plot_df = pd.DataFrame({"date": port.index})
        plot_df["Portf√∂lj"] = port.values
        if bh is not None: plot_df["Buy&Hold"] = bh.reindex(port.index).ffill().values
        if idx_curve is not None: plot_df["OMXS30 (index)"] = idx_curve.reindex(port.index).ffill().values
        plot_df = plot_df.melt("date", var_name="Series", value_name="Norm")

        st.subheader("Kapitalutveckling (normaliserad till 1.0)")
        chart = alt.Chart(plot_df).mark_line().encode(
            x=alt.X("date:T", title=None),
            y=alt.Y("Norm:Q", title="Normaliserat (x)"),
            color=alt.Color("Series:N")
        ).properties(height=420)
        st.altair_chart(chart, theme="streamlit", width="stretch")

        ts = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
        out_csv = os.path.join(OUT_DIR, f"portfolio_equity_{ts}.csv")
        plot_df.to_csv(out_csv, index=False, encoding="utf-8-sig")
        st.caption(f"Sparat kurvdata: `{out_csv}`")

with tabs[1]:
    st.subheader("Universum")
    data_dir = st.session_state.get("portfolio_dir", DEFAULT_DIR)
    files = list_json_files(data_dir)
    df = build_profiles_df(data_dir, files) if files else pd.DataFrame()
    if df.empty:
        st.info("Inga profiler hittades.")
    else:
        st.dataframe(df_brief(df, rows=50, cols=12), width="stretch")

with tabs[2]:
    st.subheader("Transaktioner")
    st.info("Om motorn returnerar aff√§rer kan vi lista dem h√§r. S√§g till s√• kopplar jag in exakt format.")
